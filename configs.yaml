defaults:
  id: 'ConvGRU_mmnist_train'
  dataset: "mmnist"
  model: "ConvGRU"      # Supports "ConvGRU", "ODEConv"
  phase: "train"
  epochs: 25
  batch_size: 4
  load_model: False
  train_test_split: 0.8
  total_frames: 2000000   # 2M frames as in CW-VAE paper
  decODE: False
  off_wandb: False
  step: 50000

  # Directories
  logdir: "logs"
  user_dir: "/home/jithen"            
  storage_dir: "scratch"
  data_dir: "datasets/MovingMNIST_video/train"    # user_dir/storage_dir/data_dir
  model_params_logdir: "model_params"             # has the form logs/<model_name>/model_params/<id>_00000xxxxx.pickle
  
  # Save & logs frequencies
  ckpt_save_freq: 2000            # Save model params every x steps
  test_log_freq: 50               # log test loss every x steps
  video_log_freq: 5000

  # Image sequence details
  resolution: 64
  train_seq: 100
  test_seq: 200
  train_in_seq: 50
  train_out_seq: 50
  test_in_seq: 50
  test_out_seq: 150
  in_channels: 3
  num_digits: 3
  n_layers: 3

  lr: 8e-4
  n_downs: 2
  decode_diff_method: 'dopri5'          # choices=['dopri5', 'euler', 'adams', 'rk4']
  frozen: True
  mem: False
  ode: False

  wandb_project: 'ODE-RL'
  wandb_entity: 'jithendaraa'
  offline: False                         # Beluga does not have internet; can set to False on cedar
  reconstruct: False                     # Set true if you want to train x frames and reconstruct back the same x frames

  neural_ode_encoder_out_ch: 128        # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2
  convgru_out_ch: 256

experimental:
  off_wandb: True

short_frames:
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  test_seq: 20
  test_in_seq: 10
  test_out_seq: 10

long_frames:
  train_seq: 100
  train_in_seq: 50
  train_out_seq: 50
  test_seq: 200
  test_in_seq: 50
  test_out_seq: 150

# Experiment 1: Train and test ConvGRU on Moving MNIST with 2M frames, 50000 steps, batch size 4
train_mmnist_cgru_len20:
  id: 'ConvGRU_mmnist_train'            # actual id is id_inframes_outframes eg. ConvGRU_mmnist_train_30_70 if training or ConvGRU_mmnist_train_30_170 is testing
  ckpt_id: 'train_mmnist_cgru_len20'
  lr: 8e-4
  ckpt_save_freq: 2000
  video_log_freq: 1000
  loss_log_freq: 100
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  conv_encoder_out_ch: 128
  convgru_out_ch: 128
  depth: 1                              # num_pairs <ConvEncode, ConvGRUCell>

test_mmnist_cgru_len20:
  id: 'ConvGRU_mmnist_test'
  ckpt_id: 'train_mmnist_cgru_len20'
  data_dir: "datasets/MovingMNIST_video/test"
  model: "ConvGRU"
  phase: "test"
  load_model: True
  test_seq: 100
  test_in_seq: 10
  test_out_seq: 90
  conv_encoder_out_ch: 128
  convgru_out_ch: 128
  depth: 1                          # num_pairs <ConvEncode, ConvGRUCell>                  # num_pairs <ConvEncode, ConvGRUCell>
 


# Experiment 2: Train and test ODEConvGRU on Moving MNIST with 50000 steps
train_mmnist_odecgru:
  id: 'ODEConv_mmnist_train'
  model: "ODEConv"
  ckpt_id: 'train_mmnist_odecgru'
  load_model: False
  ckpt_save_freq: 1000
  loss_log_freq: 50
  video_log_freq: 1000
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  n_downs: 2                            # reducing/increasing resolution per encoder/decoder layer
  conv_encoder_n_units: 32              # Out ch at end of ConvEncoder is conv_encoder_n_units * (2^n_downs)
  n_layers: 3                           # n_layers whenever create_convnet is called for ODE Func nets
  neural_ode_encoder_out_ch: 128        # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  z_sample: False

test_mmnist_odecgru:
  id: 'ODEConv_mmnist_test'
  data_dir: "datasets/MovingMNIST_video/test"
  model: "ODEConv"
  phase: "test"
  load_model: True
  frozen: True
  downsize: True                        # if True, conv_encoder will 0.5x and conv_decoder will 2x the resolution for every layer in `n_layers`
  conv_encoder_out_ch: 128              # output channels for conv encoder in models/ODEConvGRU.py
  conv_n_units: 64                      # n_units for conv encoder and conv decoder in models/ODEConvGRU.py
  n_layers: 3                           # n_layers for conv encoder and conv decoder in models/ODEConvGRU.py
  neural_ode_encoder_out_ch: 128        # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  z_sample: False

train_mmnist_odecgru_len20:
  id: 'ODEConv_mmnist_train'
  model: "ODEConv"
  ckpt_id: 'train_mmnist_odecgru_len20'
  ckpt_save_freq: 5000
  video_log_freq: 5000
  loss_log_freq: 200
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  n_downs: 2                            # reducing/increasing resolution per encoder/decoder layer
  conv_encoder_n_units: 32              # Out ch at end of ConvEncoder is conv_encoder_n_units * (2^n_downs)
  neural_ode_encoder_out_ch: 128        # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  z_sample: False

test_mmnist_odecgru_len20:
  id: 'ODEConv_mmnist_test'
  model: "ODEConv"
  ckpt_id: 'train_mmnist_odecgru_len20'
  data_dir: "datasets/MovingMNIST_video/test"
  phase: 'test'
  load_model: True
  test_seq: 100
  test_in_seq: 10
  test_out_seq: 90
  n_downs: 2                            # reducing/increasing resolution per encoder/decoder layer
  conv_encoder_n_units: 32              # Out ch at end of ConvEncoder is conv_encoder_n_units * (2^n_downs)
  neural_ode_encoder_out_ch: 128        # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  z_sample: False


# Experiment 3: Train and test ODEConvGRU-memory on Moving MNIST with 50000 steps 
train_mmnist_odecgrumem_len20:
  id: 'ODEConv_mmnist_train'
  model: "ODEConv"
  ckpt_id: 'train_mmnist_odecgrumem_len20'
  ckpt_save_freq: 5000
  video_log_freq: 5000
  mem: True
  loss_log_freq: 200
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  n_downs: 2                            # reducing/increasing resolution per encoder/decoder layer
  conv_encoder_n_units: 32              # Out ch at end of ConvEncoder is conv_encoder_n_units * (2^n_downs)
  neural_ode_encoder_out_ch: 128        # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  z_sample: False
  in_channels: 1

test_mmnist_odecgrumem_len20:
  id: 'ODEConv_mmnist_test'
  model: "ODEConv"
  ckpt_id: 'train_mmnist_odecgrumem_len20'
  data_dir: "datasets/MovingMNIST_video/test"
  phase: 'test'
  mem: True
  load_model: True
  train_seq: 100
  train_in_seq: 50
  train_out_seq: 50
  test_seq: 100
  test_in_seq: 10
  test_out_seq: 90
  n_downs: 2                            # reducing/increasing resolution per encoder/decoder layer
  conv_encoder_n_units: 32              # Out ch at end of ConvEncoder is conv_encoder_n_units * (2^n_downs)
  neural_ode_encoder_out_ch: 128        # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  z_sample: False
  in_channels: 1

# Experiment 3: Train and test S3VAE on Moving MNIST with 50000 steps 
train_mmnist_s3vae_odecgru:
  id: 's3vae_odecgru_mmnist_train'
  ckpt_id: 'train_mmnist_s3vae_odecgru'
  lr: 1e-3
  batch_size: 4
  model: 'S3VAE'
  epochs: 25
  reconstruct: True
  train_seq: 30
  train_in_seq: 15
  train_out_seq: 15
  in_channels: 3
  d_zf: 256
  d_zt: 32
  l1: 1000
  l2: 100
  l3: 1
  m: 1      # Margin for triplet loss
  loss_log_freq: 50
  video_log_freq: 1000
  ode: False
  encoder: 'odecgru'

train_mmnist_s3vae_def:
  id: 's3vae_def_mmnist_train'
  ckpt_id: 'train_mmnist_s3vae_def'
  lr: 1e-3
  batch_size: 4
  model: 'S3VAE'
  epochs: 25
  reconstruct: True
  train_seq: 30
  train_in_seq: 15
  train_out_seq: 15
  in_channels: 3
  d_zf: 256
  d_zt: 32
  l1: 1000
  l2: 100
  l3: 1
  m: 1      # Margin for triplet loss
  loss_log_freq: 50
  video_log_freq: 1000
  ode: False
  encoder: 'default'

train_mmnist_s3vaeode:
  id: 's3vaeode_mmnist_train'
  ckpt_id: 'train_mmnist_s3vaeode'
  lr: 1e-3
  batch_size: 16
  model: 'S3VAE'
  epochs: 1000
  reconstruct: True
  train_seq: 30
  train_in_seq: 15
  train_out_seq: 15
  in_channels: 3
  d_zf: 256
  d_zt: 32
  l1: 1000
  l2: 100
  l3: 1
  m: 1      # Margin for triplet loss
  loss_log_freq: 50
  video_log_freq: 1000
  ode: True



# Not supported yet
train_mmnist_vidode_len20:
  id: 'VidODE_mmnist_train'
  model: 'VidODE'
  ckpt_id: 'train_mmnist_vidode_len20'
  ckpt_save_freq: 5000
  video_log_freq: 500
  loss_log_freq: 100
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  n_downs: 2
  n_layers: 2
  
# Not supported yet
train_mmnist_sample_odecgru:      # (Not completed) Samples z0 from N(z_mu, z_sigma) instead of doing z0 = z_mu
  id: 'ODEConv_mmnist_train'
  model: "ODEConv"
  phase: "train"
  data_dir: "datasets/MovingMNIST"
  epochs: 25

  downsize: True                  # if True, conv_encoder will 0.5x and conv_decoder will 2x the resolution for every layer in `n_layers`
  conv_encoder_out_ch: 128        # output channels for conv encoder in models/ODEConvGRU.py
  conv_n_units: 64                # n_units for conv encoder and conv decoder in models/ODEConvGRU.py
  neural_ode_encoder_out_ch: 128  # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128  # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64          # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2                 # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  z_sample: True

# Not supported yet
train_mmnist_cgrudecODE:          # Not completed
  id: 'cgrudecODE_mmnist_train'            # actual id is id_inframes_outframes eg. ConvGRU_mmnist_train_30_70 if training or ConvGRU_mmnist_train_30_170 is testing
  model: "cgrudecODE"
  data_dir: "datasets/MovingMNIST"
  phase: "train"
  epochs: 10
  ckpt_save_freq: 20000
  validate_freq: 20000
  log_video_freq: 20000
  decODE: True
  z_sample: False
  loss: 'MSE'
  conv_encoder_out_ch: 128
  convgru_out_ch: 128
  depth: 1
  latent_dim: 64                               # z0 channels
