defaults:
  id: 'ConvGRU_mmnist_train'
  dataset: "mmnist"
  model: "ConvGRU"      # Supports "ConvGRU", "ODEConv"
  phase: "train"
  epochs: 25
  batch_size: 4
  load_model: False
  train_test_split: 0.8
  total_frames: 2000000   # 2M frames as in CW-VAE paper
  decODE: False
  off_wandb: False
  step: 50000
  z_sample: False
  clip: -1

  # losses
  static_contrastive: False

  # misc
  scalable: True # infer zf from just a few input frames

  # Slot attention
  slot_att: False
  num_slots: 3
  num_iterations: 3
  slot_size: 64
  unmasked: True
  rim: False

  # RIM params
  emsize: 300
  nlayers: 1
  n_hid: [300]
  sparse_comm: False
  inactive_rims: True
  num_blocks: [3]
  topk: [3]
  unit_per_rim: 100

  # S3VAE variations
  k_stat: 5 # set -1 to see all frames to infer zf; else first k frames are seen

  # Directories
  logdir: "logs"
  rundir: 'runs'
  user_dir: "/home/jithen"            
  storage_dir: "scratch"
  data_dir: "datasets/MovingMNIST_video"    # user_dir/storage_dir/data_dir
  model_params_logdir: "model_params"             # has the form logs/<model_name>/model_params/<id>_00000xxxxx.pickle
  
  # Save & logs frequencies
  ckpt_save_freq: 5000            # Save model params every x steps
  test_log_freq: 50               # log test loss every x steps
  video_log_freq: 500
  loss_log_freq: 50

  # Image sequence details
  resolution: 64
  train_seq: 100
  test_seq: 200
  train_in_seq: 50
  train_out_seq: 50
  test_in_seq: 50
  test_out_seq: 150
  in_channels: 1
  num_digits: 3
  n_layers: 3

  lr: 8e-4
  n_downs: 2
  decode_diff_method: 'dopri5'          # choices=['dopri5', 'euler', 'adams', 'rk4']
  frozen: True
  mem: False
  ode: False
  encoder: 'default'

  wandb_project: 'ODE-RL'
  wandb_entity: 'jithendaraa'
  offline: True                         # Beluga does not have internet; can set to False on cedar
  reconstruct: False                     # Set true if you want to train x frames and reconstruct back the same x frames
  extrapolate: False

  neural_ode_encoder_out_ch: 128        # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2
  convgru_out_ch: 256
  l1: 1000
  l2: 100
  l3: 1
  m: 1      # Margin for triplet loss

flownet_args:
  rgb_max: 1.
  fp16: False
  flownet_params_path: '/home/jithen/projects/rrg-ebrahimi/jithen/ODE-RL/FlowNet2_checkpoint.pth.tar'

losses:
  static_contrastive: True

experimental:
  off_wandb: True

smol:
  epochs: 1

# Experiment 1: Train and test ConvGRU on Moving MNIST with 2M frames, 50000 steps, batch size 4
train_mmnist_cgru_len20:
  # python main.py --config defaults flownet_args train_mmnist_cgru_len20 experimental
  id: 'ConvGRU_mmnist_train'            # actual id is id_inframes_outframes eg. ConvGRU_mmnist_train_30_70 if training or ConvGRU_mmnist_train_30_170 is testing
  ckpt_id: 'train_mmnist_cgru_len20'
  lr: 1e-4
  ckpt_save_freq: 5000
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  conv_encoder_out_ch: 64
  convgru_out_ch: 64
  depth: 1                              # num_pairs <ConvEncode, ConvGRUCell>

test_mmnist_cgru_len20:
  id: 'ConvGRU_mmnist_test'
  ckpt_id: 'train_mmnist_cgru_len20'
  data_dir: "datasets/MovingMNIST_video/test"
  model: "ConvGRU"
  phase: "test"
  load_model: True
  test_seq: 200
  test_in_seq: 10
  test_out_seq: 190
  conv_encoder_out_ch: 64
  convgru_out_ch: 64
  depth: 1                          # num_pairs <ConvEncode, ConvGRUCell>                  
  in_channels: 1



# Experiment 2: Train and test ODEConvGRU on Moving MNIST with 50000 steps
train_mmnist_odecgru_len20_1ch:
  id: 'ODEConv_mmnist_train'
  model: "ODEConv"
  ckpt_id: 'train_mmnist_odecgru_len20_1ch'
  lr: 1e-4
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  conv_encoder_out_ch: 64
  neural_ode_decoder_out_ch: 64        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 3                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  in_channels: 1

train_mmnist_odecgru_len20_1ch_var2:
  id: 'ODEConv_mmnist_train'
  model: "ODEConv"
  ckpt_id: 'train_mmnist_odecgru_len20_1ch_var2'
  lr: 1e-4
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  conv_encoder_out_ch: 64
  neural_ode_decoder_out_ch: 64        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 1                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  in_channels: 1

test_mmnist_odecgru_len20_1ch:
  id: 'ODEConv_mmnist_test'
  ckpt_id: 'train_mmnist_odecgru_len20_1ch'
  data_dir: "datasets/MovingMNIST_video/test"
  model: "ODEConv"
  phase: 'test'
  load_model: True
  test_seq: 100
  test_in_seq: 10
  test_out_seq: 90
  conv_encoder_out_ch: 64
  neural_ode_decoder_out_ch: 64        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 3                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  in_channels: 1



# Experiment 3: Train and test ODEConvGRU-memory on Moving MNIST with 50000 steps 
train_mmnist_odecgrumem_len20_1ch:
  id: 'ODEConv_mmnist_train'
  model: "ODEConv"
  mem: True
  ckpt_id: 'train_mmnist_odecgrumem_len20_1ch'
  ckpt_save_freq: 5000
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  conv_encoder_out_ch: 64
  neural_ode_decoder_out_ch: 64        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 3                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  in_channels: 1

test_mmnist_odecgrumem_len20_1ch:
  id: 'ODEConv_mmnist_test'
  model: "ODEConv"
  mem: True
  ckpt_id: 'train_mmnist_odecgrumem_len20_1ch'
  data_dir: "datasets/MovingMNIST_video/test"
  phase: 'test'
  load_model: True
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  test_seq: 100
  test_in_seq: 10
  test_out_seq: 90
  n_downs: 2                            # reducing/increasing resolution per encoder/decoder layer
  conv_encoder_n_units: 32              # Out ch at end of ConvEncoder is conv_encoder_n_units * (2^n_downs)
  neural_ode_encoder_out_ch: 128        # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128        # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64                # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2                       # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  z_sample: False
  in_channels: 1



# Experiment 4: S3VAE on MMNIST 50K steps (Train by reconstructing or extrapolation)
train_mmnist_recon_s3vae_def:
  # python main.py --config defaults train_mmnist_recon_s3vae_def experimental
  id: 'recon_s3vae_def_mmnist_train'
  ckpt_id: 'train_mmnist_recon_s3vae_def'
  lr: 1e-3
  model: 'S3VAE' 
  reconstruct: True
  train_seq: 40
  train_in_seq: 20 
  train_out_seq: 20
  d_zf: 256
  d_zt: 32
  encoder: 'default'
  rundir: 'runs/S3VAE'
  epochs: 1
  clip: -1
  k_stat: -1
  data_points: 10000

test_mmnist_recon_s3vae_def:
  id: 'recon_s3vae_def_mmnist_test'
  ckpt_id: 'train_mmnist_recon_s3vae_def'
  data_dir: "datasets/MovingMNIST_video/test"
  model: 'S3VAE'
  phase: 'test'
  reconstruct: True
  load_model: True
  test_seq: 200
  test_in_seq: 20
  test_out_seq: 180
  d_zf: 64
  d_zt: 64
  encoder: 'default'



# Experiment 5: S3VAE with ConvGRU MMNIST, 50K steps (Train by reconstructing or extrapolation)
train_mmnist_recon_s3vaecgru:
  # python main.py --config defaults train_mmnist_recon_s3vaecgru experimental
  id: 'recon_s3vaecgru_mmnist_train'
  ckpt_id: 'train_mmnist_recon_s3vaecgru'
  lr: 1e-4
  clip: 3e4
  model: 'S3VAE'
  reconstruct: True
  train_seq: 40
  train_in_seq: 20
  train_out_seq: 20
  d_zf: 64
  d_zt: 32
  encoder: 'cgru'
  unmasked: True
  epochs: 25
  k_stat: -1

test_mmnist_recon_s3vaecgru:
  # python main.py --config defaults flownet_args test_mmnist_recon_s3vaecgru experimental
  id: 'recon_s3vaecgru_mmnist_test'
  model: 'S3VAE'
  ckpt_id: 'train_mmnist_recon_s3vaecgru'
  data_dir: "datasets/MovingMNIST_video/test"
  phase: 'test'
  reconstruct: True
  load_model: True
  test_seq: 200
  test_in_seq: 20
  test_out_seq: 180
  d_zf: 64
  d_zt: 32
  encoder: 'cgru'



# Experiment 6: Slotted S3VAE MMNIST, 50K steps
train_mmnist_recon_s3vae_def_sa:
  # python main.py --config defaults train_mmnist_recon_s3vae_def_sa experimental
  id: 'recon_s3vae_def_sa_mmnist_train'
  ckpt_id: 'train_mmnist_recon_s3vae_def_sa'
  lr: 5e-4
  clip: 2e4
  model: 'S3VAE'
  reconstruct: True
  train_seq: 40
  train_in_seq: 20
  train_out_seq: 20
  d_zf: 256
  d_zt: 64
  slot_size: 128
  encoder: 'default'
  slot_att: True
  l1: 1000

test_mmnist_recon_s3vae_def_sa:
  # python main.py --config defaults flownet_args test_mmnist_recon_s3vae_def_sa experimental
  id: 'recon_s3vae_def_sa_mmnist_test'
  model: 'S3VAE'
  ckpt_id: 'train_mmnist_recon_s3vae_def_sa'
  data_dir: "datasets/MovingMNIST_video/test"
  phase: 'test'
  reconstruct: True
  load_model: True
  test_seq: 200
  test_in_seq: 20
  test_out_seq: 180
  d_zf: 128
  d_zt: 32
  slot_size: 32
  encoder: 'default'
  slot_att: True



# Experiment 7: Slotted S3VAE with ConvGRU MMNIST, 50K steps
train_mmnist_recon_s3vaecgru_sa:
  # python main.py --config defaults train_mmnist_recon_s3vaecgru_sa experimental
  id: 'recon_s3vaecgru_sa_mmnist_train'
  ckpt_id: 'train_mmnist_recon_s3vaecgru_sa'
  lr: 7e-4
  model: 'S3VAE'
  reconstruct: True
  train_seq: 40
  train_in_seq: 20
  train_out_seq: 20
  d_zf: 64
  d_zt: 32
  slot_size: 32
  encoder: 'cgru_sa'
  slot_att: True
  l2: 1000
  k_stat: -1

test_mmnist_recon_s3vaecgru_sa:
  # python main.py --config defaults flownet_args test_mmnist_recon_s3vaecgru_sa experimental
  id: 'recon_s3vaecgru_sa_mmnist_test'
  ckpt_id: 'train_mmnist_recon_s3vaecgru_sa'
  model: 'S3VAE'
  phase: 'test'
  data_dir: "datasets/MovingMNIST_video/test"
  reconstruct: True
  load_model: True
  test_seq: 200
  test_in_seq: 20
  test_out_seq: 180
  d_zf: 64
  d_zt: 32
  slot_size: 32
  encoder: 'cgru_sa'
  slot_att: True



# Experiment 8: RIM + Slotted S3VAE
train_mmnist_recon_rims3vae_def_sa:
  # python main.py --config defaults train_mmnist_recon_rims3vae_def_sa experimental
  id: 'recon_rims3vae_def_sa_mmnist_train'
  ckpt_id: 'train_mmnist_recon_rims3vae_def_sa'
  lr: 1e-3
  model: 'S3VAE'
  reconstruct: True
  train_seq: 40
  train_in_seq: 20
  train_out_seq: 20
  d_zf: 128
  d_zt: 32
  slot_size: 32
  encoder: 'default'
  slot_att: True
  rim: True

test_mmnist_recon_rims3vae_def_sa:
  # python main.py --config defaults flownet_args test_mmnist_recon_rims3vae_def_sa experimental
  id: 'recon_rims3vae_def_sa_mmnist_test'
  model: 'S3VAE'
  ckpt_id: 'train_mmnist_recon_rims3vae_def_sa'
  data_dir: "datasets/MovingMNIST_video/test"
  phase: 'test'
  reconstruct: True
  load_model: True
  test_seq: 200
  test_in_seq: 20
  test_out_seq: 180
  d_zf: 128
  d_zt: 32
  slot_size: 32
  encoder: 'default'
  slot_att: True
  rim: True

  
# Experiment 9: RIM + Conv. Slotted S3VAE
train_mmnist_recon_rimconvs4vae_def_sa:
  # python main.py --config defaults train_mmnist_recon_rimconvs4vae_def_sa experimental
  id: 'recon_rimconvs4vae_def_sa_mmnist_train'
  ckpt_id: 'train_mmnist_recon_rimconvs4vae_def_sa'
  lr: 1e-3
  model: 'S3VAE'
  reconstruct: True
  train_seq: 40
  train_in_seq: 20
  train_out_seq: 20
  d_zf: 64
  d_zt: 32
  slot_size: 32
  encoder: 'cgru_sa' 
  slot_att: True
  rim: True

































train_mmnist_s3vaeode:
  id: 's3vaeode_mmnist_train'
  ckpt_id: 'train_mmnist_s3vaeode'
  lr: 1e-3
  model: 'S3VAE'
  reconstruct: True
  train_seq: 30
  train_in_seq: 15
  train_out_seq: 15
  in_channels: 3
  d_zf: 256
  d_zt: 32
  loss_log_freq: 50
  ode: True

train_mmnist_s3vae_odecgru:
  id: 's3vae_odecgru_mmnist_train'
  ckpt_id: 'train_mmnist_s3vae_odecgru'
  lr: 1e-3
  model: 'S3VAE'
  reconstruct: True
  train_seq: 40
  train_in_seq: 20
  train_out_seq: 20
  in_channels: 3
  d_zf: 128
  d_zt: 32
  loss_log_freq: 50
  encoder: 'odecgru'

# Not supported yet
train_mmnist_vidode_len20:
  id: 'VidODE_mmnist_train'
  model: 'VidODE'
  ckpt_id: 'train_mmnist_vidode_len20'
  ckpt_save_freq: 5000
  video_log_freq: 500
  loss_log_freq: 100
  train_seq: 20
  train_in_seq: 10
  train_out_seq: 10
  n_downs: 2
  n_layers: 2
  
# Not supported yet
train_mmnist_sample_odecgru:      # (Not completed) Samples z0 from N(z_mu, z_sigma) instead of doing z0 = z_mu
  id: 'ODEConv_mmnist_train'
  model: "ODEConv"
  phase: "train"
  data_dir: "datasets/MovingMNIST"
  epochs: 25

  downsize: True                  # if True, conv_encoder will 0.5x and conv_decoder will 2x the resolution for every layer in `n_layers`
  conv_encoder_out_ch: 128        # output channels for conv encoder in models/ODEConvGRU.py
  conv_n_units: 64                # n_units for conv encoder and conv decoder in models/ODEConvGRU.py
  neural_ode_encoder_out_ch: 128  # output channels for ode_encoder_func in models/ODEConvGRU.py
  neural_ode_decoder_out_ch: 128  # output channels for ode_decoder_func in models/ODEConvGRU.py
  neural_ode_n_units: 64          # n_units for the convnet in ode_encoder_func and ode_decoder_func
  n_ode_layers: 2                 # n_layers for the convnet in ode_encoder_func and ode_decoder_func
  z_sample: True

# Not supported yet
train_mmnist_cgrudecODE:          # Not completed
  id: 'cgrudecODE_mmnist_train'            # actual id is id_inframes_outframes eg. ConvGRU_mmnist_train_30_70 if training or ConvGRU_mmnist_train_30_170 is testing
  model: "cgrudecODE"
  data_dir: "datasets/MovingMNIST"
  phase: "train"
  epochs: 10
  ckpt_save_freq: 20000
  validate_freq: 20000
  log_video_freq: 20000
  decODE: True
  z_sample: False
  loss: 'MSE'
  conv_encoder_out_ch: 128
  convgru_out_ch: 128
  depth: 1
  latent_dim: 64                               # z0 channels
